{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import Series,DataFrame\n",
    "import os , random , sys, time\n",
    "from urllib.parse import urlparse\n",
    "from selenium import webdriver \n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-penalty",
   "metadata": {},
   "source": [
    "## LongIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get('https://www.linkedin.com/uas/login')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open ('user-passw.txt')\n",
    "lines = file.readlines()\n",
    "username = lines[0]\n",
    "password = lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "elementID = browser.find_element_by_id(\"username\")\n",
    "elementID.send_keys(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "elementID = browser.find_element_by_id(\"password\")\n",
    "elementID.send_keys(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "elementID.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-substitute",
   "metadata": {},
   "source": [
    "## Profiles Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_profile = open ('profileLinks.txt')\n",
    "profilelLinks = []\n",
    "\n",
    "for visitProfile in file_profile :\n",
    "    fullLink =  visitProfile \n",
    "    profilelLinks.append(fullLink)\n",
    "\n",
    "print(profilelLinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-bridal",
   "metadata": {},
   "source": [
    "## LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "df = DataFrame(columns = ['NAME', 'COMPANY' , 'JOB_TITLE','LOCATION','PROFILE_TITLE', 'LINK'])\n",
    "\n",
    "for link in profilelLinks:\n",
    "\n",
    "    browser.get(link)\n",
    "    scroll_pause_time = 5\n",
    "    \n",
    "    #get scroll height \n",
    "    last_height = browser.execute_script('return document.body.scrollHeight')\n",
    "    time.sleep(scroll_pause_time)\n",
    "    \n",
    "    for i in range(2):\n",
    "        #scroll down to bottom\n",
    "        #browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        scheight = .1\n",
    "        while scheight < 9.9:\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight/%s);\" % scheight)\n",
    "            scheight += .01\n",
    "            \n",
    "\n",
    "        #wait to load page \n",
    "       # time.sleep(scroll_pause_time)\n",
    "\n",
    "        #calculate new scroll height and compare with last scroll height \n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        las_height = new_height\n",
    "    \n",
    "    src = browser.page_source\n",
    "    soup = BeautifulSoup(src,'html5lib')\n",
    "    \n",
    "    #name\n",
    "    name_div= soup.find('div',{'class':'flex-1 mr5'} )\n",
    "    name_loc = name_div.find_all('ul')\n",
    "    name = name_loc[0].find('li').get_text().strip()\n",
    "    print(name)\n",
    "    \n",
    "    \n",
    "    #loc\n",
    "    loc = name_loc[1].find('li').get_text().strip()\n",
    "    print(loc)\n",
    "    \n",
    "    \n",
    "    #Profile_title\n",
    "    profile_title = name_div.find('h2').get_text().strip()\n",
    "    print(profile_title)\n",
    "\n",
    "   \n",
    "    #job title-1(Profiles with one possition in the company )\n",
    "    exp_section = soup.find('section' , {'id':\"experience-section\"})\n",
    "    exp_ul = exp_section.find('ul')\n",
    "    li_tags = exp_ul.find('li' , {\"class\" :\"pv-entity__position-group-pager pv-profile-section__list-item ember-view\"})\n",
    "    a_tags = li_tags.find('a')\n",
    "    job_title = a_tags.find('h3').get_text().strip()\n",
    "    \n",
    "    \n",
    "    #job title-2 (Profile with Different position in the same company)\n",
    "    if 'Company Name' in job_title or 'Nome da empresa' in job_title :\n",
    "       \n",
    "        ul_tags = li_tags.find('ul')\n",
    "        h3_tags = ul_tags.find('h3')\n",
    "        span_tag= h3_tags.find_all('span')\n",
    "        job_title = span_tag[1].get_text().strip()\n",
    "        print(job_title)\n",
    "        \n",
    "       \n",
    "        #Company name-2 (Profile with different position in the same company)\n",
    "        span_tags2 = li_tags.find('h3')\n",
    "        company_name= span_tags2.find_all('span')\n",
    "        company_name = company_name[1].get_text().strip() \n",
    "        \n",
    "        \n",
    "        #Company name-1 (Profiles with same position in the same company)\n",
    "    else:\n",
    "        print(job_title)\n",
    "        \n",
    "        company_name= a_tags.find_all('p')[1].get_text().strip().split('\\n') #there is 2 paragraf , the second one will be selected \n",
    "        company_name = company_name[0]\n",
    "        print(company_name)\n",
    "        \n",
    "    \n",
    "    dic ={'NAME' :name,'COMPANY' :company_name, 'JOB_TITLE' :job_title,'LOCATION':loc,'PROFILE_TITLE':profile_title,  'LINK':fullLink }\n",
    "    \n",
    "    \n",
    "    df=df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "df.head(20)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:\\\\yyy\\\\yyyy\\\\yyyy\\\\yyy\\\\yyy\\\\yyyyy' , sep= ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-flight",
   "metadata": {},
   "source": [
    "## Sales Navigator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "df = DataFrame(columns = ['NAME', 'COMPANY' , 'JOB_TITLE','LOCATION','PROFILE_TITLE', 'LINK'])\n",
    "\n",
    "for link in profilelLinks:\n",
    "    \n",
    "    browser.get(link)\n",
    "    scroll_pause_time = 5\n",
    "\n",
    "    #get scroll height \n",
    "    last_height = browser.execute_script('return document.body.scrollHeight')\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "    for i in range(1):\n",
    "    #scroll down to bottom\n",
    "    #browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        scheight = .1\n",
    "        while scheight < 9.9:\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight/%s);\" % scheight)\n",
    "            scheight += .01\n",
    "\n",
    "\n",
    "        #wait to load page \n",
    "        # time.sleep(scroll_pause_time)\n",
    "\n",
    "        #calculate new scroll height and compare with last scroll height \n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        las_height = new_height\n",
    "\n",
    "    src = browser.page_source\n",
    "    soup = BeautifulSoup(src,'html5lib')\n",
    "\n",
    "    #name\n",
    "    name_div = soup.find('div',{'class':\"profile-topcard full-width pb5\"} )\n",
    "    name_dl = name_div.find('dl',{'class':\"profile-topcard-person-entity__content-text vertical-align-top pl4\"}) \n",
    "    name_dt = name_dl.find('dt' , {'class':'flex align-items-center'})\n",
    "    name = name_dt.find('span').get_text().strip()\n",
    "\n",
    "    print(name)\n",
    "\n",
    "    #loc\n",
    "\n",
    "    loc_dl = name_dl.find('dd', {'class' : 'mt4 mb0'})\n",
    "    loc = name_dl.find('div' , {'class' : \"profile-topcard__location-data inline t-14 t-black--light mr5\"}).get_text().strip()\n",
    "    print(loc)\n",
    "\n",
    "    #Profile_title\n",
    "    profile_title = name_dl.find('dd',{'class': 'mt2'}).get_text().strip()\n",
    "    print(profile_title)\n",
    "\n",
    "    #job title\n",
    "\n",
    "    exp_dl = name_div.find('dl' , {'class' :'overflow-hidden'})\n",
    "    exp_dd = exp_dl.find('dd' , {'class' :'profile-topcard__current-positions flex mt3'})\n",
    "    exp_div = exp_dd.find('div',{'class' :'profile-topcard__summary-position flex align-items-top' })\n",
    "    job_title = exp_div.find('span',{'class' :\"profile-topcard__summary-position-title\" }).get_text().strip()\n",
    "\n",
    "    print(job_title)\n",
    "\n",
    "    company_span = exp_div.find('span', {'class' : 'align-self-center'})\n",
    "    \n",
    "    company_name = company_span.find('a')\n",
    "    \n",
    "    if company_name == None:\n",
    "        \n",
    "        company_name == None\n",
    "        \n",
    "        print(company_name)\n",
    "    else:\n",
    "        company_name = company_name.get_text().strip()\n",
    "        \n",
    "        print(company_name)\n",
    "        \n",
    "\n",
    "\n",
    "    #DataFrame\n",
    "    dic ={'NAME' :name,'COMPANY' :company_name, 'JOB_TITLE' :job_title,'LOCATION':loc,'PROFILE_TITLE':profile_title,  'LINK':link }\n",
    "\n",
    "    df=df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "df.head(20)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-qualification",
   "metadata": {},
   "source": [
    "# Saving dfProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:\\\\xxxx\\\\xxxx\\\\xxxxx\\\\xxxx\\\\xxxx\\\\xxxx\\\\xxxx' , sep= ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
